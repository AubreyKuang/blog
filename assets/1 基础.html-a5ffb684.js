import{_ as e,V as i,W as s,a0 as r}from"./framework-91a010c2.js";const t={},a=r('<h1 id="redis" tabindex="-1"><a class="header-anchor" href="#redis" aria-hidden="true">#</a> Redis</h1><p>基于内存的数据库，对数据的读写操作都是在内存中完成，因此<strong>读写速度非常快</strong>，常用于<strong>缓存，消息队列、分布式锁等场景</strong>。</p><p>提供了多种数据类型来支持不同的业务场景，比如 String(字符串)、Hash(哈希)、 List (列表)、Set(集合)、Zset(有序集合)等，并且对数据类型的操作都是<strong>原子性</strong>的，因为执行命令由单线程负责的，不存在并发竞争的问题。</p><p>支持<strong>事务 、持久化、Lua 脚本、多种集群方案（主从复制模式、哨兵模式、切片机群模式）、发布/订阅模式，内存淘汰机制、过期删除机制</strong>等等。</p><h3 id="" tabindex="-1"><a class="header-anchor" href="#" aria-hidden="true">#</a></h3><h3 id="和-memcached比较" tabindex="-1"><a class="header-anchor" href="#和-memcached比较" aria-hidden="true">#</a> 和 Memcached比较</h3><p><strong>共同点</strong>：</p><ol><li>都是基于内存的数据库，一般都用来当做缓存使用。</li><li>都有过期策略。</li><li>两者的性能都非常高。</li></ol><p><strong>区别</strong>：</p><ol><li>Redis 支持的数据类型更丰富（String、Hash、List、Set、ZSet），而 Memcached 只支持最简单的 key-value 数据类型；</li><li>Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，而 Memcached 没有持久化功能，数据全部存在内存之中，Memcached 重启或者挂掉后，数据就没了；</li><li>Redis 原生支持集群模式，Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；</li><li>Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持；</li></ol><h3 id="why-redis" tabindex="-1"><a class="header-anchor" href="#why-redis" aria-hidden="true">#</a> why Redis</h3><ol><li><p>高性能</p><p>用户第一次访问 MySQL 中的某些数据。这个过程会比较慢，因为是从硬盘上读取的。将该用户访问的数据缓存在 Redis 中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了，操作 Redis 缓存就是直接操作内存，所以速度相当快。</p></li><li><p>高并发</p><p>单台设备的 Redis 的 QPS（Query Per Second，每秒钟处理完请求的次数） 是 MySQL 的 10 倍，Redis 单机的 QPS 能轻松破 10w，而 MySQL 单机的 QPS 很难破 1w。</p><p>所以，直接访问 Redis 能够承受的请求是远远大于直接访问 MySQL 的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。</p></li></ol><h2 id="redis数据结构" tabindex="-1"><a class="header-anchor" href="#redis数据结构" aria-hidden="true">#</a> Redis数据结构</h2><p><img src="https://cdn.jsdelivr.net/gh/KoryKL/pictures@main/blog/image-20230409103945572.png" alt="image-20230409103945572" loading="lazy"></p><h3 id="string-字符串" tabindex="-1"><a class="header-anchor" href="#string-字符串" aria-hidden="true">#</a> <strong>String（字符串）</strong></h3><p>底层的数据结构实现主要是 SDS（简单动态字符串）</p><ul><li><strong>SDS 不仅可以保存文本数据，还可以保存音频、视频等二进制数据</strong>。因为 SDS 使用 len 属性的值而不是空字符来判断字符串是否结束，并且 SDS 的所有 API 都会以处理二进制的方式来处理 SDS 存放在 buf[] 数组里的数据。</li><li><strong>SDS 获取字符串长度的时间复杂度是 O(1)</strong>。SDS 结构里用 len 属性记录了字符串长度，所以复杂度为 O(1)。而C 语言的字符串并不记录自身长度，所以获取长度的复杂度为 O(n)</li><li><strong>Redis 的 SDS API 是安全的，拼接字符串不会造成缓冲区溢出</strong>。因为 SDS 在拼接字符串之前会检查 SDS 空间是否满足要求，如果空间不够会自动扩容，所以不会导致缓冲区溢出的问题。</li></ul><h3 id="hash-哈希" tabindex="-1"><a class="header-anchor" href="#hash-哈希" aria-hidden="true">#</a> <strong>Hash（哈希）</strong></h3><p>由<strong>压缩列表或哈希表</strong>实现的：</p><ul><li>如果哈希类型元素个数小于 512 个（默认值，可由 hash-max-ziplist-entries 配置），所有值小于 64 字节（默认值，可由 hash-max-ziplist-value 配置）的话，Redis 会使用<strong>压缩列表</strong>作为 Hash 类型的底层数据结构；</li><li>如果哈希类型元素不满足上面条件，Redis 会使用<strong>哈希表</strong>作为 Hash 类型的底层数据结构。</li></ul><p><strong>在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了</strong>。</p><h3 id="list-列表" tabindex="-1"><a class="header-anchor" href="#list-列表" aria-hidden="true">#</a> <strong>List（列表）</strong></h3><p><strong>双向链表或压缩列表</strong>实现的：</p><ul><li>如果列表的<strong>元素个数</strong>小于 512 个（默认值，可由 list-max-ziplist-entries 配置），列表<strong>每个元素的值都小于</strong> 64 字节（默认值，可由 list-max-ziplist-value 配置），Redis 会使用<strong>压缩列表</strong>作为 List 类型的底层数据结构；</li><li>如果列表的元素不满足上面的条件，Redis 会使用<strong>双向链表</strong>作为 List 类型的底层数据结构；</li></ul><p><strong>在 Redis 3.2 版本之后，List 数据类型底层数据结构就只由 quicklist 实现</strong></p><h3 id="set-集合" tabindex="-1"><a class="header-anchor" href="#set-集合" aria-hidden="true">#</a> <strong>Set（集合）</strong></h3><p>由<strong>哈希表或整数集合</strong>实现的：</p><ul><li>如果集合中的元素都是整数且元素个数小于 512 （默认值，set-maxintset-entries配置）个，Redis 会使用<strong>整数集合</strong>作为 Set 类型的底层数据结构；</li><li>如果集合中的元素不满足上面条件，则 Redis 使用<strong>哈希表</strong>作为 Set 类型的底层数据结构。</li></ul><h3 id="zset-有序集合" tabindex="-1"><a class="header-anchor" href="#zset-有序集合" aria-hidden="true">#</a> <strong>Zset（有序集合）</strong></h3><p>由<strong>压缩列表或跳表</strong>实现的：</p><ul><li>如果有序集合的元素个数小于 128 个，并且每个元素的值小于 64 字节时，Redis 会使用<strong>压缩列表</strong>作为 Zset 类型的底层数据结构；</li><li>如果有序集合的元素不满足上面的条件，Redis 会使用<strong>跳表</strong>作为 Zset 类型的底层数据结构；</li></ul><p><strong>在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。</strong></p><h2 id="redis线程模型" tabindex="-1"><a class="header-anchor" href="#redis线程模型" aria-hidden="true">#</a> Redis线程模型</h2><h3 id="单线程" tabindex="-1"><a class="header-anchor" href="#单线程" aria-hidden="true">#</a> 单线程</h3><p><strong>指的是「接收客户端请求-&gt;解析请求 -&gt;进行数据读写等操作-&gt;发送数据给客户端」这个过程是由一个线程（主线程）来完成的</strong></p><p>但是，<strong>Redis 程序并不是单线程的</strong>，Redis 在启动的时候，是会<strong>启动后台线程</strong>（BIO）的：</p><ul><li><p>Redis 在 2.6 版本，会启动 2 个后台线程，分别处理关闭文件、AOF 刷盘这两个任务；</p></li><li><p>在 4.0 版本之后，新增了一个新的后台线程，用来异步释放 Redis 内存，也就是 lazyfree 线程。</p><blockquote><p>因此，当我们要删除一个大 key 的时候，不要使用 del 命令删除，因为 del 是在主线程处理的，这样会导致 Redis 主线程卡顿，因此我们应该使用 unlink 命令来异步删除大key。</p></blockquote></li></ul><p>之所以 Redis 为「关闭文件、AOF 刷盘、释放内存」这些任务创建单独的线程来处理，是因为这些任务的操作都是很耗时的，如果把这些任务都放在主线程来处理，那么 Redis 主线程就很容易发生阻塞，这样就无法处理后续的请求了。</p><p>后台线程相当于一个消费者，生产者把耗时任务丢到任务队列中，消费者（BIO）不停轮询这个队列，拿出任务就去执行对应的方法即可。</p><p><strong>关闭文件、AOF 刷盘、释放内存这三个任务都有各自的任务队列</strong>：</p><ul><li>BIO_CLOSE_FILE，关闭文件任务队列：当队列有任务后，后台线程会调用 close(fd) ，将文件关闭；</li><li>BIO_AOF_FSYNC，AOF刷盘任务队列：当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到队列中。当发现队列有任务后，后台线程会调用 fsync(fd)，将 AOF 文件刷盘，</li><li>BIO_LAZY_FREE，lazy free 任务队列：当队列有任务后，后台线程会 free(obj) 释放对象 / free(dict) 删除数据库所有对象 / free(skiplist) 释放跳表对象；</li></ul><h3 id="初始化" tabindex="-1"><a class="header-anchor" href="#初始化" aria-hidden="true">#</a> 初始化</h3><ul><li>首先，调用 epoll_create() 创建一个 epoll 对象和调用 socket() 创建一个服务端 socket</li><li>然后，调用 bind() 绑定端口和调用 listen() 监听该 socket；</li><li>然后，将调用 epoll_ctl() 将 listen socket 加入到 epoll，同时注册「连接事件」处理函数。</li></ul><p>初始化完后，主线程就进入到一个<strong>事件循环函数</strong>，主要会做以下事情：</p><ul><li>首先，先调用<strong>处理发送队列函数</strong>，看是发送队列里是否有任务，如果有发送任务，则通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会注册写事件处理函数，等待 epoll_wait 发现可写后再处理 。</li><li>接着，调用 epoll_wait 函数等待事件的到来： <ul><li>如果是<strong>连接事件</strong>到来，则会调用<strong>连接事件处理函数</strong>，该函数会做这些事情：调用 accpet 获取已连接的 socket -&gt; 调用 epoll_ctl 将已连接的 socket 加入到 epoll -&gt; 注册「读事件」处理函数；</li><li>如果是<strong>读事件</strong>到来，则会调用<strong>读事件处理函数</strong>，该函数会做这些事情：调用 read 获取客户端发送的数据 -&gt; 解析命令 -&gt; 处理命令 -&gt; 将客户端对象添加到发送队列 -&gt; 将执行结果写到发送缓存区等待发送；</li><li>如果是<strong>写事件</strong>到来，则会调用<strong>写事件处理函数</strong>，该函数会做这些事情：通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会继续注册写事件处理函数，等待 epoll_wait 发现可写后再处理 。</li></ul></li></ul><h3 id="单线程还快的原因" tabindex="-1"><a class="header-anchor" href="#单线程还快的原因" aria-hidden="true">#</a> 单线程还快的原因</h3><ul><li>Redis 的大部分操作<strong>都在内存中完成</strong>，并且采用了高效的数据结构，因此 Redis 瓶颈可能是机器的内存或者网络带宽，而并非 CPU，既然 CPU 不是瓶颈，那么自然就采用单线程的解决方案了；</li><li>Redis 采用单线程模型可以<strong>避免了多线程之间的竞争</strong>，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。</li><li>Redis 采用了 <strong>I/O 多路复用机制</strong>处理大量的客户端 Socket 请求，IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。</li></ul><h3 id="之前为什么单线程-为什么又多线程" tabindex="-1"><a class="header-anchor" href="#之前为什么单线程-为什么又多线程" aria-hidden="true">#</a> 之前为什么单线程，为什么又多线程？</h3><p><strong>CPU 并不是制约 Redis 性能表现的瓶颈所在</strong>，更多情况下是受到内存大小和网络I/O的限制，所以 Redis 核心网络模型使用单线程并没有什么问题，如果你想要使用服务的多核CPU，可以在一台服务器上启动多个节点或者采用分片集群的方式。</p><p>使用了单线程后，可维护性高，多线程模型虽然在某些方面表现优异，但是它却引入了程序执行顺序的不确定性，带来了并发读写的一系列问题，<strong>增加了系统复杂度、同时可能存在线程切换、甚至加锁解锁、死锁造成的性能损耗</strong>。</p><p>换成多线程的原因：</p><p>虽然 Redis 的主要工作（网络 I/O 和执行命令）一直是单线程模型，但是<strong>在 Redis 6.0 版本之后，也采用了多个 I/O 线程来处理网络请求</strong>，<strong>这是因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I/O 的处理上</strong>。</p><p>所以为了提高网络 I/O 的并行度，Redis 6.0 对于网络 I/O 采用多线程来处理。**但是对于命令的执行，Redis 仍然使用单线程来处理，*<em>所以大家*<em>不要误解</em></em> Redis 有多线程同时执行命令。</p><p>Redis 6.0 版本支持的 I/O 多线程特性，默认情况下 I/O 多线程只针对发送响应数据（write client socket），并不会以多线程的方式处理读请求（read client socket）。要想开启多线程处理客户端读请求，就需要把 Redis.conf 配置文件中的 io-threads-do-reads 配置项设为 yes。</p><h2 id="redis持久化" tabindex="-1"><a class="header-anchor" href="#redis持久化" aria-hidden="true">#</a> Redis持久化</h2><p>为了保证内存中的数据不会丢失，Redis 实现了数据持久化的机制，这个机制会把数据存储到磁盘，这样在 Redis 重启就能够从磁盘中恢复原有的数据。</p><p>Redis 共有三种数据持久化的方式：</p><h3 id="_1⃣️-aof日志" tabindex="-1"><a class="header-anchor" href="#_1⃣️-aof日志" aria-hidden="true">#</a> 1⃣️ AOF日志</h3><p>每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里；</p><p>Redis 重启时，会读取该文件记录的命令，然后逐一执行命令的方式来进行数据恢复。</p><h4 id="为什么先执行命令-再把数据写入日志呢" tabindex="-1"><a class="header-anchor" href="#为什么先执行命令-再把数据写入日志呢" aria-hidden="true">#</a> 为什么先执行命令，再把数据写入日志呢？</h4><p>好处：</p><ul><li><strong>避免额外的检查开销</strong>：因为如果先将写操作命令记录到 AOF 日志里，再执行该命令的话，如果当前的命令语法有问题，那么如果不进行命令语法检查，该错误的命令记录到 AOF 日志里后，Redis 在使用日志恢复数据时，就可能会出错。</li><li><strong>不会阻塞当前写操作命令的执行</strong>：因为当写操作命令执行成功后，才会将命令记录到 AOF 日志。</li></ul><p>风险：</p><ul><li><strong>数据可能会丢失：</strong> 执行写操作命令和记录日志是两个过程，那当 Redis 在还没来得及将命令写入到硬盘时，服务器发生宕机了，这个数据就会有丢失的风险。</li><li><strong>可能阻塞其他操作：</strong> 由于写操作命令执行成功后才记录到 AOF 日志，所以不会阻塞当前命令的执行，但因为 AOF 日志也是在主线程中执行，所以当 Redis 把日志文件写入磁盘的时候，还是会阻塞后续的操作无法执行。</li></ul><blockquote><p>写回策略有几种？</p><img src="https://cdn.jsdelivr.net/gh/KoryKL/pictures@main/blog/image-20230409133535494.png" alt="image-20230409133535494" style="zoom:33%;"></blockquote><ol><li>Redis 执行完写操作命令后，会将命令追加到 server.aof_buf 缓冲区；</li><li>然后通过 write() 系统调用，将 aof_buf 缓冲区的数据写入到 AOF 文件，此时数据并没有写入到硬盘，而是拷贝到了内核缓冲区 page cache，等待内核将数据写入硬盘；</li><li>具体内核缓冲区的数据什么时候写入到硬盘，由内核决定。</li></ol><p>Redis 提供了 3 种写回硬盘的策略，控制的就是上面说的第三步的过程。</p><p><img src="https://cdn.jsdelivr.net/gh/KoryKL/pictures@main/blog/image-20230409134035687.png" alt="image-20230409134035687" loading="lazy"></p><h4 id="aof-日志过大-会触发什么机制" tabindex="-1"><a class="header-anchor" href="#aof-日志过大-会触发什么机制" aria-hidden="true">#</a> AOF 日志过大，会触发什么机制？</h4><p>AOF 日志是一个文件，随着执行的写操作命令越来越多，文件的大小会越来越大。 如果当 AOF 日志文件过大就会带来性能问题，比如重启 Redis 后，需要读 AOF 文件的内容以恢复数据，如果文件过大，整个恢复的过程就会很慢。</p><p>所以，Redis 为了避免 AOF 文件越写越大，提供了 <strong>AOF 重写机制</strong>，当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。</p><p>AOF 重写机制是在重写时，读取当前数据库中的所有键值对，然后将每一个键值对<strong>用一条命令</strong>记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。相当于压缩了 AOF 文件，使得文件体积变小了。</p><h5 id="重写日志的过程" tabindex="-1"><a class="header-anchor" href="#重写日志的过程" aria-hidden="true">#</a> 重写日志的过程？</h5><p><strong>由后台子进程 *bgrewriteaof* 来完成的</strong>，好处：</p><ul><li><p>子进程进行 AOF 重写期间，主进程可以继续处理命令请求，从而避免阻塞主进程；</p></li><li><p>子进程带有主进程的数据副本，这里使用<strong>子进程而不是线程</strong>，因为如果是使用线程，多线程之间会共享内存，那么在修改共享内存数据的时候，需要通过加锁来保证数据的安全，而这样就会降低性能。</p><p>而使用子进程，创建子进程时，父子进程是共享内存数据的，不过这个<strong>共享的内存只能以只读的方式</strong>，而当父子进程任意一方修改了该共享内存，就会发生「写时复制」，于是父子进程就有了独立的数据副本，就不用加锁来保证数据安全。</p></li></ul><p>触发重写机制后，主进程就会创建重写 AOF 的子进程，此时父子进程共享物理内存，重写子进程只会对这个内存进行只读，重写 AOF 子进程会读取数据库里的所有数据，并逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志（新的 AOF 文件）。</p><p><strong>但是重写过程中，主进程依然可以正常处理命令</strong>，重写 AOF 日志过程中，如果主进程修改了已经存在 key-value，那么会发生写时复制，此时这个 key-value 数据在子进程的内存数据就跟主进程的内存数据不一致了，这时要怎么办呢？</p><p>为了解决这种数据不一致问题，Redis 设置了一个 <strong>AOF 重写缓冲区</strong>，这个缓冲区在创建 bgrewriteaof 子进程之后开始使用。</p><p>在重写 AOF 期间，当 Redis 执行完一个写命令之后，它会<strong>同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」</strong>。</p><blockquote><p>在 bgrewriteaof 子进程执行 AOF 重写期间，主进程需要执行以下三个工作:</p></blockquote><ul><li>执行客户端发来的命令；</li><li>将执行后的写命令追加到 「AOF 缓冲区」；</li><li>将执行后的写命令追加到 「AOF 重写缓冲区」；</li></ul><p>当子进程完成 AOF 重写工作（<em>扫描数据库中所有数据，逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志</em>）后，会向主进程发送一条信号，信号是进程间通讯的一种方式，且是异步的。</p><p>主进程收到该信号后，会调用一个信号处理函数，该函数主要做以下工作：</p><ul><li>将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中，使得新旧两个 AOF 文件所保存的数据库状态一致；</li><li>新的 AOF 的文件进行改名，覆盖现有的 AOF 文件。</li></ul><p>信号函数执行完后，主进程就可以继续像往常一样处理命令了。</p><h3 id="_2⃣️-rdb-快照" tabindex="-1"><a class="header-anchor" href="#_2⃣️-rdb-快照" aria-hidden="true">#</a> 2⃣️ <strong>RDB 快照</strong></h3><p>将某一时刻的内存数据，以二进制的方式写入磁盘；</p><p>在 Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些，因为直接将 RDB 文件读入内存就可以，不需要像 AOF 那样还需要额外执行操作命令的步骤才能恢复数据。</p><blockquote><p>因为 AOF 日志记录的是操作命令，不是实际的数据，所以用 AOF 方法做故障恢复时，需要全量把日志都执行一遍，一旦 AOF 日志非常多，势必会造成 Redis 的恢复操作缓慢。</p></blockquote><h4 id="是否线程阻塞" tabindex="-1"><a class="header-anchor" href="#是否线程阻塞" aria-hidden="true">#</a> 是否线程阻塞？</h4><p>提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave，他们的区别就在于是否在「主线程」里执行：</p><ul><li>执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，<strong>会阻塞主线程</strong>；</li><li>执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以<strong>避免主线程的阻塞</strong>；</li></ul><h4 id="快照的时候可以修改数据" tabindex="-1"><a class="header-anchor" href="#快照的时候可以修改数据" aria-hidden="true">#</a> 快照的时候可以修改数据？</h4><p><strong>可以继续处理操作命令</strong>的，也就是数据是能被修改的，关键的技术就在于<strong>写时复制技术（Copy-On-Write, COW）。</strong></p><p>执行 bgsave 命令的时候，会通过 fork() 创建子进程，此时子进程和父进程是共享同一片内存数据的，因为创建子进程的时候，会复制父进程的页表，但是页表指向的物理内存还是一个，此时如果主线程执行读操作，则主线程和 bgsave 子进程互相不影响。</p><h3 id="_3⃣️-混合持久化方式" tabindex="-1"><a class="header-anchor" href="#_3⃣️-混合持久化方式" aria-hidden="true">#</a> 3⃣️ <strong>混合持久化方式</strong></h3><p>Redis 4.0 新增的方式，集成了 AOF 和 RBD 的优点；既保证了 Redis 重启速度，又降低数据丢失风险。</p><p>RDB 优点是数据恢复速度快，但是快照的频率不好把握。频率太低，丢失的数据就会比较多，频率太高，就会影响性能。</p><p>AOF 优点是丢失数据少，但是数据恢复不快。</p>',100),n=[a];function l(o,d){return i(),s("div",null,n)}const g=e(t,[["render",l],["__file","1 基础.html.vue"]]);export{g as default};
